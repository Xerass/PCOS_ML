{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3699828d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jomar\\VSCode\\ML\\BasicML\\ML\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import random, json\n",
    "import numpy as np\n",
    "import torch, os\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Subset, WeightedRandomSampler\n",
    "from torchvision import transforms, datasets\n",
    "from PIL import Image\n",
    "import timm\n",
    "from tqdm import tqdm\n",
    "from typing import List, Tuple, Dict, Optional\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, roc_curve, precision_recall_curve, confusion_matrix, classification_report\n",
    "\n",
    "try:\n",
    "    from pytorch_grad_cam import GradCAM\n",
    "    from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "    _HAS_GRADCAM = True\n",
    "except Exception:\n",
    "    _HAS_GRADCAM = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded21e77",
   "metadata": {},
   "source": [
    "Create Config metrics for easier variable changing later down the line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f32f157",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = Path(\"data\")   # <-- set path\n",
    "TRAIN_DIR, TEST_DIR = DATA_ROOT/\"train\", DATA_ROOT/\"test\"\n",
    "MODEL_DIR = Path(\"models_ultrasound\"); MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "BACKBONE = \"efficientnet_b0\"\n",
    "IMG_SIZE, BATCH_SIZE = 224, 12\n",
    "NUM_EPOCHS, FREEZE_EPOCHS = 30, 5\n",
    "LR_HEAD, LR_BACKBONE, WEIGHT_DECAY = 1e-3, 1e-4, 1e-5\n",
    "PATIENCE_ES, VAL_SPLIT, RANDOM_SEED = 6, 0.15, 42\n",
    "POS_LABEL_IDX, NUM_WORKERS = 0, 2\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "USE_AMP = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b822bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for reproduction purposes set all variable random seeds\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8d118c",
   "metadata": {},
   "source": [
    "Data transformations, to further augment the data and be better prepared for actual traning and generalization towards messy irl data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "288b5824",
   "metadata": {},
   "outputs": [],
   "source": [
    "#since expected input are grayscale (ultrasounds) reproduce it into RGB channels so it can work on pretrained models\n",
    "class Ensure3Channel:\n",
    "    def __call__(self, img: Image.Image) -> Image.Image:\n",
    "        return img.convert(\"RGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75a1c9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#necessary transforms for more generalized to prevent overfitting and be better suited to tackle real world input\n",
    "#actual values is very small so it should still be similar to original image\n",
    "train_tf = transforms.Compose([\n",
    "    Ensure3Channel(),\n",
    "    #randomly crops parts of the images\n",
    "    transforms.RandomResizedCrop(IMG_SIZE, scale=(0.80, 1.0)),\n",
    "    #applies a small rotation\n",
    "    transforms.RandomAffine(degrees=10, translate=(0.05,0.05), shear=5),\n",
    "    #flips image left to right 50% of the time\n",
    "    transforms.RandomHorizontalFlip(0.5),\n",
    "    #adds a little color jitter\n",
    "    transforms.ColorJitter(brightness=0.10, contrast=0.10),\n",
    "    #adds a slight blur to simulate low res scans\n",
    "    transforms.GaussianBlur(kernel_size=(3,3), sigma=(0.1,1.0)),\n",
    "    transforms.ToTensor(),\n",
    "    #normalizes the pixels for the expected ImageNet Model\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]), \n",
    "])\n",
    "\n",
    "val_tf = transforms.Compose([\n",
    "    Ensure3Channel(),\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b198f4",
   "metadata": {},
   "source": [
    "Create the data loaders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd19d4e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['infected', 'notinfected'] Train counts: {'infected': 676, 'notinfected': 960}\n"
     ]
    }
   ],
   "source": [
    "def build_dataloaders(train_dir, test_dir):\n",
    "    #really convenient for subfolder since it expects already that sub dirs are the classes.\n",
    "    train_full = datasets.ImageFolder(str(train_dir),transform = train_tf)\n",
    "    class_names = train_full.classes\n",
    "\n",
    "    #get total length of dataset\n",
    "    n = len(train_full)\n",
    "    #get indices and shuffle the images around\n",
    "    idx = list(range(n)); random.shuffle(idx)\n",
    "    #create size of val via split\n",
    "    val_n = int(n * VAL_SPLIT)\n",
    "    #slice the respective train val splits\n",
    "    val_idx, tr_idx = idx[:val_n], idx[val_n:]\n",
    "\n",
    "    #generate subsets for each\n",
    "    train_subset = Subset(train_full, tr_idx)\n",
    "    #create the imagefolder with the transform beforehand for val\n",
    "    train_val = datasets.ImageFolder(str(train_dir), transform=val_tf)\n",
    "    val_subset = Subset(train_val, val_idx)\n",
    "\n",
    "    tr_labels = [train_full.samples[i][1] for i in tr_idx]\n",
    "    class_counts = {class_names[i]: tr_labels.count(i) for i in range(len(class_names))}\n",
    "\n",
    "    #from looking at the data there seems to be a ~7:11 ratio for infected vs non, use a sampler to remedy the imbalance\n",
    "    sampler = None\n",
    "    if all(c > 0 for c in class_counts.values()):\n",
    "        weights = np.array([1.0 / class_counts[class_names[y]] for y in tr_labels], dtype=np.float32)\n",
    "        sampler = WeightedRandomSampler(weights, num_samples=len(weights), replacement=True)\n",
    "\n",
    "    train_loader = DataLoader(train_subset, batch_size=BATCH_SIZE, shuffle=(sampler is None),\n",
    "                              sampler=sampler, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "    val_loader   = DataLoader(val_subset, batch_size=BATCH_SIZE, shuffle=False,\n",
    "                              num_workers=NUM_WORKERS, pin_memory=True)\n",
    "    test_ds = datasets.ImageFolder(str(test_dir), transform=val_tf)\n",
    "    test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False,\n",
    "                             num_workers=NUM_WORKERS, pin_memory=True)\n",
    "    \n",
    "    return train_loader, val_loader, test_loader, class_names, class_counts\n",
    "\n",
    "train_loader, val_loader, test_loader, class_names, class_counts = build_dataloaders(TRAIN_DIR, TEST_DIR)\n",
    "print(\"Classes:\", class_names, \"Train counts:\", class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431ea5ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
