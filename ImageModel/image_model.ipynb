{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3699828d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jomar\\VSCode\\ML\\BasicML\\ML\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import random, json\n",
    "import numpy as np\n",
    "import torch, os\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Subset, WeightedRandomSampler\n",
    "from torchvision import transforms, datasets\n",
    "from PIL import Image\n",
    "import timm\n",
    "from tqdm import tqdm\n",
    "from typing import List, Tuple, Dict, Optional\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, roc_curve, precision_recall_curve, confusion_matrix, classification_report\n",
    "\n",
    "try:\n",
    "    from pytorch_grad_cam import GradCAM\n",
    "    from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "    _HAS_GRADCAM = True\n",
    "except Exception:\n",
    "    _HAS_GRADCAM = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded21e77",
   "metadata": {},
   "source": [
    "Create Config metrics for easier variable changing later down the line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f32f157",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = Path(\"/path/to/data\")   # <-- set path\n",
    "TRAIN_DIR, TEST_DIR = DATA_ROOT/\"train\", DATA_ROOT/\"test\"\n",
    "MODEL_DIR = Path(\"models_ultrasound\"); MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "BACKBONE = \"efficientnet_b0\"\n",
    "IMG_SIZE, BATCH_SIZE = 224, 12\n",
    "NUM_EPOCHS, FREEZE_EPOCHS = 30, 5\n",
    "LR_HEAD, LR_BACKBONE, WEIGHT_DECAY = 1e-3, 1e-4, 1e-5\n",
    "PATIENCE_ES, VAL_SPLIT, RANDOM_SEED = 6, 0.15, 42\n",
    "POS_LABEL_IDX, NUM_WORKERS = 1, 2\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "USE_AMP = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b822bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for reproduction purposes set all variable random seeds\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "288b5824",
   "metadata": {},
   "outputs": [],
   "source": [
    "#since expected input are grayscale (ultrasounds) reproduce it into RGB channels so it can work on pretrained models\n",
    "class Ensure3Channel:\n",
    "    def __call__(self, img: Image.Image) -> Image.Image:\n",
    "        return img.convert(\"RGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a1c9d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
